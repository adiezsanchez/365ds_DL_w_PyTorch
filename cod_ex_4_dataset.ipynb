{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e380dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 100\n",
      "First sample input shape: torch.Size([5])\n",
      "First sample label shape: torch.Size([])\n",
      "First sample: (tensor([-1.0600, -0.4253, -0.3714,  0.3015,  0.5628]), tensor(2.4584))\n",
      "Training dataset size: 80\n",
      "Testing dataset size: 20\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, random_split\n",
    "\n",
    "# 1. Create sample input data (X) as a PyTorch tensor with 100 samples and 5 features (random values).\n",
    "X = torch.randn(100, 5)\n",
    "\n",
    "# 2. Create sample output labels (y) as a PyTorch tensor with 100 labels (random values).\n",
    "y = torch.randn(100)\n",
    "\n",
    "# 3. Define a custom Dataset class called 'MySampleDataset' that inherits from torch.utils.data.Dataset.\n",
    "class MySampleDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        # Initialize the dataset with features and labels.\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        assert len(self.features) == len(self.labels), \"Number of samples must match!\"\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset.\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve the feature and label at the given index.\n",
    "        feature = self.features[index]\n",
    "        label = self.labels[index]\n",
    "        return feature, label\n",
    "\n",
    "# 4. Create an instance of your 'MySampleDataset' using the sample data X and y.\n",
    "dataset = MySampleDataset(X, y)\n",
    "\n",
    "# 5. Print the size of the dataset using the __len__() method.\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "\n",
    "# 6. Access and print the first sample (input and label) from the dataset using indexing.\n",
    "first_sample_input, first_sample_label = dataset[0]\n",
    "print(\"First sample input shape:\", first_sample_input.shape)\n",
    "print(\"First sample label shape:\", first_sample_label.shape)\n",
    "print(\"First sample:\", (first_sample_input, first_sample_label))\n",
    "\n",
    "# 7. Split the dataset into training and testing sets with an 80/20 ratio.\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# 8. Print the sizes of the training and testing datasets.\n",
    "print(\"Training dataset size:\", len(train_dataset))\n",
    "print(\"Testing dataset size:\", len(test_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLO_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
