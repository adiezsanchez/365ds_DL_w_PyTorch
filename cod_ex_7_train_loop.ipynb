{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1af910c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 28.4417\n",
      "Epoch [2/10], Loss: 19.7351\n",
      "Epoch [3/10], Loss: 13.6938\n",
      "Epoch [4/10], Loss: 9.5019\n",
      "Epoch [5/10], Loss: 6.5931\n",
      "Epoch [6/10], Loss: 4.5749\n",
      "Epoch [7/10], Loss: 3.1744\n",
      "Epoch [8/10], Loss: 2.2027\n",
      "Epoch [9/10], Loss: 1.5284\n",
      "Epoch [10/10], Loss: 1.0605\n",
      "\n",
      "Learned parameters:\n",
      "linear.weight: tensor([[1.7135]])\n",
      "linear.bias: tensor([-0.0794])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. Define a simple linear regression model.\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# 2. Create some dummy training data (features X and labels y).\n",
    "X_train = torch.tensor([[1.0], [2.0], [3.0], [4.0]], dtype=torch.float32)\n",
    "y_train = torch.tensor([[2.0], [4.0], [6.0], [8.0]], dtype=torch.float32)\n",
    "\n",
    "# 3. Instantiate the LinearRegression model with input and output dimensions of 1.\n",
    "input_dim = 1\n",
    "output_dim = 1\n",
    "model = LinearRegression(input_dim, output_dim)\n",
    "\n",
    "# 4. Define the loss function (Mean Squared Error Loss).\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 5. Define the optimizer (Stochastic Gradient Descent) with a learning rate of 0.01.\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 6. Implement the training loop. Run for a few epochs (e.g., 10).\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass: compute predictions on the training data.\n",
    "    outputs = model(X_train)\n",
    "\n",
    "    # Calculate the loss between the predictions and the true labels.\n",
    "    loss = criterion(outputs, y_train)\n",
    "\n",
    "    # Backward pass: compute the gradients of the loss with respect to the model parameters.\n",
    "    optimizer.zero_grad()  # Clear previous gradients\n",
    "    loss.backward()       # Compute gradients\n",
    "    optimizer.step()  # Update model parameters\n",
    "\n",
    "    # Print the loss for each epoch to observe the training progress.\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 7. After training, print the learned parameters (weights and bias) of the linear layer.\n",
    "print(\"\\nLearned parameters:\")\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f'{name}: {param.data}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microglia_GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
